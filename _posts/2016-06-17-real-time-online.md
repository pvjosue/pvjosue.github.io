---
title: "Real-time online adaption for robust instrument tracking and pose estimation"
collection: publications
date: 2016-10-17
venue: 'MICCAI'
citation: 'N. Rieke, D. J. Tan, F. Tombari, J. Page Vizca√≠no, C. Amat di San Filippo, A. Eslami, N. Navab &quot;Real-time online adaption for robust instrument tracking and pose estimation.&quot; In <i>MICCAI 16</i>.'
---

 [[Article]](https://link.springer.com/chapter/10.1007/978-3-319-46720-7_49) 
 <!-- [[Project Page]](https://sjenni.github.io/LearningToSpotArtifacts/) [[Code]](https://github.com/sjenni/LearningToSpotArtifacts)  -->

## Abstract

We propose a novel method for instrument tracking in Retinal Microsurgery (RM) which is apt to withstand the challenges of RM visual sequences in terms of varying illumination conditions and blur. At the same time, the method is general enough to deal with different background and tool appearances. The proposed approach relies on two random forests to, respectively, track the surgery tool and estimate its 2D pose. Robustness to photometric distortions and blur is provided by a specific online refinement stage of the offline trained forest, which makes our method also capable of generalizing to unseen backgrounds and tools. In addition, a peculiar framework for merging together the predictions of tracking and pose is employed to improve the overall accuracy. Remarkable advantages in terms of accuracy over the state-of-the-art are shown on two benchmarks.